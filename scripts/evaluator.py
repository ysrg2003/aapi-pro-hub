#!/usr/bin/env python3
"""
AAPI Pro Hub - Ø§Ù„Ù…Ù‚ÙŠÙ…/Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹
ÙŠÙ‚Ø§Ø±Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ SPEC ÙˆÙŠØ­Ø¯Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙØ´Ù„
"""

import json
import argparse
import os
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Tuple

class Evaluator:
    """Ø§Ù„Ù…Ù‚ÙŠÙ… - ÙŠÙ‚Ø§Ø±Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ SPEC"""
    
    def __init__(self):
        self.max_iterations = 5
    
    def evaluate(self, spec: Dict, logs: str, exit_code: int, iteration: int) -> Dict[str, Any]:
        """
        ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ù‚Ø§Ø¨Ù„ SPEC
        
        Returns:
            dict with:
                - passed: bool
                - failures: list of issues
                - recommendations: list of fixes
        """
        failures = []
        recommendations = []
        
        # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† exit code
        if exit_code != 0:
            failures.append({
                'type': 'execution_error',
                'severity': 'critical',
                'description': f'ÙØ´Ù„ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨Ø®Ø±ÙˆØ¬ Ø±Ù…Ø²: {exit_code}',
                'logs': logs[:500],  # Ø£ÙˆÙ„ 500 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª
            })
            recommendations.append('ÙØ­Øµ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù€ compilation')
        
        # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù‚Ø¨ÙˆÙ„
        for criterion in spec.get('acceptance_criteria', []):
            if not self._check_criterion(criterion, logs):
                failures.append({
                    'type': 'spec_mismatch',
                    'severity': 'high',
                    'description': f'Ù„Ù… ÙŠØªØ­Ù‚Ù‚: {criterion}',
                })
                recommendations.append(f'ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ Ù„ØªØ­Ù‚ÙŠÙ‚: {criterion}')
        
        # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        files_needed = spec.get('files_needed', [])
        for file_name in files_needed:
            if not self._check_file_exists(file_name, logs):
                failures.append({
                    'type': 'missing_file',
                    'severity': 'high',
                    'description': f'Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø§Ù‚Øµ: {file_name}',
                })
                recommendations.append(f'Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: {file_name}')
        
        # 4. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚Ø±Ø§Ø±
        passed = len([f for f in failures if f['severity'] == 'critical']) == 0
        
        # 5. Ø¥Ø°Ø§ ÙØ´Ù„Ù†Ø§ ÙˆÙ„Ù… Ù†ØµÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ØŒ Ø§Ù‚ØªØ±Ø­ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
        if not passed and iteration < self.max_iterations:
            recommendations.append(f'Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© (attempt {iteration + 1}/{self.max_iterations})')
        
        result = {
            'passed': passed,
            'iteration': iteration,
            'failures': failures,
            'recommendations': recommendations,
            'should_retry': not passed and iteration < self.max_iterations,
        }
        
        return result
    
    def _check_criterion(self, criterion: str, logs: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¹ÙŠØ§Ø± ÙˆØ§Ø­Ø¯"""
        logs_lower = logs.lower()
        
        # ÙƒÙ„Ù…Ø§Øª ØªØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ù„ÙØ´Ù„
        failure_keywords = [
            'error', 'fail', 'exception', 'traceback',
            'syntax error', 'type error', 'reference error',
            'undefined', 'not found', 'cannot', 'Ù„Ø§ ÙŠÙ…ÙƒÙ†'
        ]
        
        for keyword in failure_keywords:
            if keyword in logs_lower and criterion.lower() not in logs_lower:
                return False
        
        return True
    
    def _check_file_exists(self, file_name: str, logs: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª
        return file_name in logs
    
    def generate_patch_instructions(self, failures: List[Dict], spec: Dict) -> List[Dict]:
        """
        Ø¥Ù†Ø´Ø§Ø¡ ØªØ¹Ù„ÙŠÙ…Ø§Øª_patch Ù„Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
        
        ØµÙŠØºØ©:
        - file: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
        - operation: insert | replace | delete
        - after_line / start_line / end_line
        - content: Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        """
        patches = []
        
        for failure in failures:
            if failure['type'] == 'missing_file':
                # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯
                patches.append({
                    'operation': 'create',
                    'file': failure.get('file', 'main.py'),
                    'content': f'# Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯: {failure.get("description", "")}',
                    'reason': failure['description'],
                })
            
            elif failure['type'] == 'execution_error':
                # ØªØ­Ù„ÙŠÙ„ Ø®Ø·Ø£ Ø§Ù„ØªÙ†ÙÙŠØ°
                error_msg = failure.get('logs', '')
                patches.append({
                    'operation': 'analyze',
                    'error_message': error_msg,
                    'suggestion': 'ÙØ­Øµ ÙˆØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ³Ø¨Ø¨ Ø§Ù„Ø®Ø·Ø£',
                })
        
        return patches
    
    def create_feedback_for_ai(self, result: Dict, spec: Dict) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        
        feedback = f"""
=== ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø·Ù„Ø¨ # iteration {result.get('iteration', 1)} ===

Ø§Ù„Ø­Ø§Ù„Ø©: {'âœ… Ù†Ø¬Ø­' if result['passed'] else 'âŒ ÙØ´Ù„'}

"""
        
        if result.get('failures'):
            feedback += "=== Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ===\n"
            for i, failure in enumerate(result['failures'], 1):
                feedback += f"{i}. [{failure['severity']}] {failure['description']}\n"
        
        if result.get('recommendations'):
            feedback += "\n=== Ø§Ù„ØªÙˆØµÙŠØ§Øª ===\n"
            for rec in result['recommendations']:
                feedback += f"- {rec}\n"
        
        feedback += f"""
=== Ù…Ø¹Ù„ÙˆÙ…Ø§Øª SPEC ===
- Ø§Ù„Ù„ØºØ©: {spec.get('language')}
- Ø§Ù„Ù†ÙŠØ©: {spec.get('intent')}
- Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {spec.get('files_needed')}
"""
        
        return feedback


def run_tests(commands: List[str], cwd: str) -> Tuple[int, str]:
    """ØªØ´ØºÙŠÙ„ Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    all_output = []
    
    for cmd in commands:
        try:
            result = subprocess.run(
                cmd,
                shell=True,
                cwd=cwd,
                capture_output=True,
                text=True,
                timeout=60
            )
            all_output.append(f"$ {cmd}\n{result.stdout}\n{result.stderr}")
            
            if result.returncode != 0:
                return result.returncode, '\n'.join(all_output)
        except subprocess.TimeoutExpired:
            return -1, f"Timeout: {cmd}"
        except Exception as e:
            return -1, str(e)
    
    return 0, '\n'.join(all_output)


def main():
    parser = argparse.ArgumentParser(description='Ø§Ù„Ù…Ù‚ÙŠÙ… - ÙŠÙ‚Ø§Ø±Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ SPEC')
    parser.add_argument('--spec', required=True, help='Ù…Ù„Ù SPEC')
    parser.add_argument('--logs', required=True, help='Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª')
    parser.add_argument('--iteration', default='1', help='Ø±Ù‚Ù… Ø§Ù„ØªÙƒØ±Ø§Ø±')
    parser.add_argument('--output', default='evaluation.json', help='Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬')
    
    args = parser.parse_args()
    
    # ØªØ­Ù…ÙŠÙ„ SPEC
    with open(args.spec, 'r', encoding='utf-8') as f:
        spec = json.load(f)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
    logs_path = Path(args.logs)
    logs = ""
    if logs_path.exists():
        for log_file in logs_path.rglob('*.log'):
            with open(log_file, 'r', encoding='utf-8') as f:
                logs += f.read() + '\n'
    
    # ØªØ­Ø¯ÙŠØ¯ exit code Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª
    exit_code = 0
    if 'error' in logs.lower() or 'fail' in logs.lower():
        exit_code = 1
    
    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    evaluator = Evaluator()
    result = evaluator.evaluate(spec, logs, exit_code, int(args.iteration))
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªØ¹Ù„ÙŠÙ…Ø§Øª_patch
    if not result['passed']:
        patches = evaluator.generate_patch_instructions(result['failures'], spec)
        result['patches'] = patches
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        result['ai_feedback'] = evaluator.create_feedback_for_ai(result, spec)
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
    if result['passed']:
        print("âœ… Ù†Ø¬Ø­ Ø§Ù„Ø·Ù„Ø¨!")
    else:
        print(f"âŒ ÙØ´Ù„ (attempt {args.iteration})")
        for rec in result.get('recommendations', []):
            print(f"   â†’ {rec}")
    
    print(f"\nğŸ“„ saved to: {output_path}")


if __name__ == '__main__':
    main()
